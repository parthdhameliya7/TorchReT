{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import timm\n",
    "import albumentations\n",
    "\n",
    "from torchret import Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = {\n",
    "    'epochs' : 10,\n",
    "    'lr' : 1e-4,\n",
    "    'eta_min' : 1e-6,\n",
    "    'T_0' : 10,\n",
    "    'epochs' : 10,\n",
    "    'step_scheduler_after' : 'epoch',\n",
    "\n",
    "    'train_bs' : 64,\n",
    "    'valid_bs' : 64,\n",
    "\n",
    "    'num_workers' : 0,\n",
    "    'pin_memory' : False,\n",
    "\n",
    "    'model_name' : 'resnet10t',\n",
    "    'pretrained' : True,\n",
    "    'num_classes' : 10,\n",
    "    'in_channels' : 1,\n",
    "    'device' : 'mps',\n",
    "\n",
    "    'model_path' : 'digit-recognizer.pt',\n",
    "    'save_best_model' : 'on_eval_metric',\n",
    "    'save_on_metric' : 'accuracy',\n",
    "    'save_model_at_every_epoch' : False,\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitRecognizerDataset:\n",
    "    def __init__(self, df, augmentations):\n",
    "        self.df = df\n",
    "        self.targets = df.label.values\n",
    "        self.df = self.df.drop(columns=[\"label\"])\n",
    "        self.augmentations = augmentations\n",
    "\n",
    "        self.images = self.df.to_numpy(dtype=np.float32).reshape((-1, 28, 28))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        targets = self.targets[item]\n",
    "        image = self.images[item]\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "\n",
    "        return {\n",
    "            \"images\": torch.tensor(image, dtype=torch.float),\n",
    "            \"targets\": torch.tensor(targets, dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_augs = albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "                max_pixel_value=255.0,\n",
    "                p=1.0,\n",
    "            ),\n",
    "        ],\n",
    "        p=1.0,\n",
    "    )\n",
    "\n",
    "valid_augs = albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "                max_pixel_value=255.0,\n",
    "                p=1.0,\n",
    "            ),\n",
    "        ],\n",
    "        p=1.0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "train, test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "train_dataset = DigitRecognizerDataset(df = train, augmentations = train_augs)\n",
    "valid_dataset = DigitRecognizerDataset(df = test, augmentations = valid_augs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "data = train_dataset[789]\n",
    "\n",
    "plt.imshow(data['images'].permute(1, 2, 0))\n",
    "plt.title(data['targets'].item());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitRecognizerModel(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = timm.create_model(\n",
    "            model_name = configs['model_name'],\n",
    "            pretrained=configs['pretrained'],\n",
    "            in_chans=configs['in_channels'],\n",
    "            num_classes=configs['num_classes'],\n",
    "        )\n",
    "\n",
    "        self.num_workers = configs['num_workers']\n",
    "        self.pin_memory = configs['pin_memory']\n",
    "        self.step_scheduler_after = configs['step_scheduler_after']\n",
    "\n",
    "        self.model_path = configs['model_path']\n",
    "        self.save_best_model = configs['save_best_model']\n",
    "        self.save_on_metric = configs['save_on_metric']\n",
    "        self.save_model_at_every_epoch = configs['save_model_at_every_epoch']\n",
    "\n",
    "    def monitor_metrics(self, outputs, targets):\n",
    "        device = targets.device.type\n",
    "        outputs = np.argmax(outputs.cpu().detach().numpy(), axis=1)\n",
    "        targets = targets.cpu().detach().numpy()\n",
    "        acc = metrics.accuracy_score(targets, outputs)\n",
    "        acc = torch.tensor(acc).float()\n",
    "        f1_score = metrics.f1_score(targets, outputs, average = 'macro')\n",
    "        f1_score = torch.tensor(f1_score)\n",
    "        return {\"accuracy\": acc, 'f1_score' : f1_score}\n",
    "    \n",
    "    def monitor_loss(self, outputs, targets):\n",
    "        loss = nn.CrossEntropyLoss()(outputs, targets)\n",
    "        return loss\n",
    "\n",
    "    def fetch_optimizer(self):\n",
    "        opt = torch.optim.SGD(\n",
    "            self.parameters(),\n",
    "            lr=configs['lr'],\n",
    "            momentum=0.9,\n",
    "        )\n",
    "        sch = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            opt, \n",
    "            T_0 = configs['T_0'],\n",
    "            eta_min = configs['eta_min'],\n",
    "            T_mult= 1\n",
    "        )\n",
    "        return opt, sch\n",
    "\n",
    "    def forward(self, images, targets=None):\n",
    "        x = self.model(images)\n",
    "        if targets is not None:\n",
    "            loss = self.monitor_loss(x, targets)\n",
    "            metrics = self.monitor_metrics(x, targets)\n",
    "            return x, loss, metrics\n",
    "        return x, 0, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 525/525 [00:34<00:00, 15.41it/s, accuracy=0.551, current_lr=0.0001, epoch=1, f1_score=0.529, loss=1.412928, stage=train]\n",
      "100%|██████████| 132/132 [00:03<00:00, 40.83it/s, accuracy=0.793, epoch=1, f1_score=0.771, loss=0.746358, stage=eval]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved at digit-recognizer.pt\n",
      "Model was saved based on_eval_metric with 0.79296875 accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 525/525 [00:27<00:00, 19.39it/s, accuracy=0.842, current_lr=0.0001, epoch=2, f1_score=0.826, loss=0.574852, stage=train]\n",
      "100%|██████████| 132/132 [00:02<00:00, 54.15it/s, accuracy=0.895, epoch=2, f1_score=0.881, loss=0.396337, stage=eval]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved at digit-recognizer.pt\n",
      "Model was saved based on_eval_metric with 0.89453125 accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 525/525 [00:25<00:00, 20.94it/s, accuracy=0.901, current_lr=0.0001, epoch=3, f1_score=0.889, loss=0.350486, stage=train]\n",
      "100%|██████████| 132/132 [00:02<00:00, 59.52it/s, accuracy=0.925, epoch=3, f1_score=0.917, loss=0.270227, stage=eval]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved at digit-recognizer.pt\n",
      "Model was saved based on_eval_metric with 0.9248342803030303 accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 525/525 [00:28<00:00, 18.28it/s, accuracy=0.925, current_lr=0.0001, epoch=4, f1_score=0.916, loss=0.262384, stage=train]\n",
      "100%|██████████| 132/132 [00:02<00:00, 54.16it/s, accuracy=0.942, epoch=4, f1_score=0.936, loss=0.206515, stage=eval]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved at digit-recognizer.pt\n",
      "Model was saved based on_eval_metric with 0.9424715909090909 accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 525/525 [00:28<00:00, 18.69it/s, accuracy=0.938, current_lr=0.0001, epoch=5, f1_score=0.929, loss=0.209896, stage=train]\n",
      "100%|██████████| 132/132 [00:02<00:00, 48.45it/s, accuracy=0.952, epoch=5, f1_score=0.947, loss=0.172329, stage=eval]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved at digit-recognizer.pt\n",
      "Model was saved based on_eval_metric with 0.9515861742424242 accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 525/525 [00:25<00:00, 20.25it/s, accuracy=0.949, current_lr=0.0001, epoch=6, f1_score=0.941, loss=0.175484, stage=train]\n",
      "100%|██████████| 132/132 [00:02<00:00, 55.37it/s, accuracy=0.957, epoch=6, f1_score=0.955, loss=0.150149, stage=eval]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved at digit-recognizer.pt\n",
      "Model was saved based on_eval_metric with 0.9572679924242424 accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 525/525 [00:23<00:00, 22.09it/s, accuracy=0.955, current_lr=0.0001, epoch=7, f1_score=0.949, loss=0.152511, stage=train]\n",
      "100%|██████████| 132/132 [00:02<00:00, 59.42it/s, accuracy=0.962, epoch=7, f1_score=0.958, loss=0.135381, stage=eval]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved at digit-recognizer.pt\n",
      "Model was saved based on_eval_metric with 0.9620028409090909 accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 525/525 [00:23<00:00, 22.56it/s, accuracy=0.96, current_lr=0.0001, epoch=8, f1_score=0.953, loss=0.136915, stage=train] \n",
      "100%|██████████| 132/132 [00:02<00:00, 61.03it/s, accuracy=0.964, epoch=8, f1_score=0.961, loss=0.124579, stage=eval]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved at digit-recognizer.pt\n",
      "Model was saved based on_eval_metric with 0.9641335227272727 accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 525/525 [00:22<00:00, 22.84it/s, accuracy=0.964, current_lr=0.0001, epoch=9, f1_score=0.959, loss=0.118164, stage=train]\n",
      "100%|██████████| 132/132 [00:02<00:00, 59.64it/s, accuracy=0.967, epoch=9, f1_score=0.963, loss=0.113713, stage=eval]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved at digit-recognizer.pt\n",
      "Model was saved based on_eval_metric with 0.9672111742424242 accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 525/525 [00:23<00:00, 22.16it/s, accuracy=0.967, current_lr=0.0001, epoch=10, f1_score=0.96, loss=0.110489, stage=train] \n",
      "100%|██████████| 132/132 [00:02<00:00, 50.82it/s, accuracy=0.968, epoch=10, f1_score=0.966, loss=0.107840, stage=eval]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved at digit-recognizer.pt\n",
      "Model was saved based on_eval_metric with 0.9683948863636364 accuracy\n"
     ]
    }
   ],
   "source": [
    "model = DigitRecognizerModel()\n",
    "model.fit(train_dataset, valid_dataset, device = configs['device'], epochs = configs['epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
