{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import timm\n",
    "import albumentations\n",
    "\n",
    "from torchret import Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = {\n",
    "    'epochs' : 10,\n",
    "    'lr' : 1e-4,\n",
    "    'eta_min' : 1e-6,\n",
    "    'T_0' : 10,\n",
    "    'epochs' : 10,\n",
    "    'step_scheduler_after' : 'epoch',\n",
    "\n",
    "    'train_bs' : 64,\n",
    "    'valid_bs' : 64,\n",
    "\n",
    "    'num_workers' : 0,\n",
    "    'pin_memory' : False,\n",
    "\n",
    "    'model_name' : 'resnet10t',\n",
    "    'pretrained' : True,\n",
    "    'num_classes' : 10,\n",
    "    'in_channels' : 1,\n",
    "    'device' : 'mps',\n",
    "\n",
    "    'model_path' : 'digit-recognizer.pt',\n",
    "    'save_best_model' : 'on_eval_metric',\n",
    "    'save_on_metric' : 'accuracy',\n",
    "    'save_model_at_every_epoch' : False,\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitRecognizerDataset:\n",
    "    def __init__(self, df, augmentations):\n",
    "        self.df = df\n",
    "        self.targets = df.label.values\n",
    "        self.df = self.df.drop(columns=[\"label\"])\n",
    "        self.augmentations = augmentations\n",
    "\n",
    "        self.images = self.df.to_numpy(dtype=np.float32).reshape((-1, 28, 28))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        targets = self.targets[item]\n",
    "        image = self.images[item]\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "\n",
    "        return {\n",
    "            \"images\": torch.tensor(image, dtype=torch.float),\n",
    "            \"targets\": torch.tensor(targets, dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_augs = albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "                max_pixel_value=255.0,\n",
    "                p=1.0,\n",
    "            ),\n",
    "        ],\n",
    "        p=1.0,\n",
    "    )\n",
    "\n",
    "valid_augs = albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "                max_pixel_value=255.0,\n",
    "                p=1.0,\n",
    "            ),\n",
    "        ],\n",
    "        p=1.0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "train, test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "train_dataset = DigitRecognizerDataset(df = train, augmentations = train_augs)\n",
    "valid_dataset = DigitRecognizerDataset(df = test, augmentations = valid_augs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "data = train_dataset[789]\n",
    "\n",
    "plt.imshow(data['images'].permute(1, 2, 0))\n",
    "plt.title(data['targets'].item());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitRecognizerModel(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = timm.create_model(\n",
    "            model_name = configs['model_name'],\n",
    "            pretrained=configs['pretrained'],\n",
    "            in_chans=configs['in_channels'],\n",
    "            num_classes=configs['num_classes'],\n",
    "        )\n",
    "\n",
    "        self.num_workers = configs['num_workers']\n",
    "        self.pin_memory = configs['pin_memory']\n",
    "        self.step_scheduler_after = configs['step_scheduler_after']\n",
    "\n",
    "        self.model_path = configs['model_path']\n",
    "        self.save_best_model = configs['save_best_model']\n",
    "        self.save_on_metric = configs['save_on_metric']\n",
    "        self.save_model_at_every_epoch = configs['save_model_at_every_epoch']\n",
    "\n",
    "    def monitor_metrics(self, outputs, targets):\n",
    "        device = targets.device.type\n",
    "        outputs = np.argmax(outputs.cpu().detach().numpy(), axis=1)\n",
    "        targets = targets.cpu().detach().numpy()\n",
    "        acc = metrics.accuracy_score(targets, outputs)\n",
    "        acc = torch.tensor(acc, device=device)\n",
    "        f1_score = metrics.f1_score(targets, outputs, average = 'macro')\n",
    "        f1_score = torch.tensor(f1_score)\n",
    "        return {\"accuracy\": acc, 'f1_score' : f1_score}\n",
    "    \n",
    "    def monitor_loss(self, outputs, targets):\n",
    "        loss = nn.CrossEntropyLoss()(outputs, targets)\n",
    "        return loss\n",
    "\n",
    "    def fetch_optimizer(self):\n",
    "        opt = torch.optim.SGD(\n",
    "            self.parameters(),\n",
    "            lr=configs['lr'],\n",
    "            momentum=0.9,\n",
    "        )\n",
    "        sch = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            opt, \n",
    "            T_0 = configs['T_0'],\n",
    "            eta_min = configs['eta_min'],\n",
    "            T_mult= 1\n",
    "        )\n",
    "        return opt, sch\n",
    "\n",
    "    def forward(self, images, targets=None):\n",
    "        x = self.model(images)\n",
    "        if targets is not None:\n",
    "            loss = self.monitor_loss(x, targets)\n",
    "            metrics = self.monitor_metrics(x, targets)\n",
    "            return x, loss, metrics\n",
    "        return x, 0, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 525/525 [05:19<00:00,  1.64it/s, accuracy=0.556, current_lr=0.0001, epoch=1, f1_score=0.535, loss=1.398602, stage=train] \n",
      "100%|██████████| 132/132 [00:50<00:00,  2.62it/s, accuracy=0.794, epoch=1, f1_score=0.776, loss=0.718105, stage=eval]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved at digit-recognizer.pt\n",
      "Model was saved based on_eval_metric with 0.7943892045454546 accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 525/525 [2:39:04<00:00, 18.18s/it, accuracy=0.847, current_lr=9.76e-5, epoch=2, f1_score=0.832, loss=0.548536, stage=train]      \n",
      "100%|██████████| 132/132 [00:48<00:00,  2.70it/s, accuracy=0.892, epoch=2, f1_score=0.881, loss=0.390909, stage=eval]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved at digit-recognizer.pt\n",
      "Model was saved based on_eval_metric with 0.8916903409090909 accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 525/525 [04:35<00:00,  1.90it/s, accuracy=0.904, current_lr=9.05e-5, epoch=3, f1_score=0.892, loss=0.342536, stage=train]\n",
      "100%|██████████| 132/132 [00:50<00:00,  2.64it/s, accuracy=0.921, epoch=3, f1_score=0.912, loss=0.275005, stage=eval]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved at digit-recognizer.pt\n",
      "Model was saved based on_eval_metric with 0.9208096590909091 accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 525/525 [07:55<00:00,  1.10it/s, accuracy=0.927, current_lr=7.96e-5, epoch=4, f1_score=0.918, loss=0.253626, stage=train]  \n",
      "100%|██████████| 132/132 [00:50<00:00,  2.63it/s, accuracy=0.935, epoch=4, f1_score=0.93, loss=0.226295, stage=eval] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved at digit-recognizer.pt\n",
      "Model was saved based on_eval_metric with 0.935250946969697 accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 525/525 [05:19<00:00,  1.64it/s, accuracy=0.939, current_lr=6.58e-5, epoch=5, f1_score=0.931, loss=0.211728, stage=train]\n",
      "100%|██████████| 132/132 [00:53<00:00,  2.45it/s, accuracy=0.943, epoch=5, f1_score=0.939, loss=0.199566, stage=eval]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved at digit-recognizer.pt\n",
      "Model was saved based on_eval_metric with 0.9431818181818182 accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 19/525 [00:15<09:35,  1.14s/it, accuracy=0.956, current_lr=5.05e-5, epoch=6, f1_score=0.95, loss=0.158139, stage=train] "
     ]
    }
   ],
   "source": [
    "model = DigitRecognizerModel()\n",
    "model.fit(train_dataset, valid_dataset, device = configs['device'], epochs = configs['epochs'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
